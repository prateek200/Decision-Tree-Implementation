{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules that are required in this notebook\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading iris dataset\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(iris.data)\n",
    "df.columns = [\"sl\", \"sw\", 'pl', 'pw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to find label for a value\n",
    "#if MIN_Value <=val < (m + Mean_Value) / 2 then it is assigned label a\n",
    "#if (m + Mean_Value) <=val < Mean_Value then it is assigned label b\n",
    "#if (Mean_Value) <=val < (Mean_Value + MAX_Value)/2 then it is assigned label c\n",
    "#if (Mean_Value + MAX_Value)/2 <=val <= MAX_Value  then it is assigned label d\n",
    "\n",
    "def label(val, *boundaries):\n",
    "    if (val < boundaries[0]):\n",
    "        return 'a'\n",
    "    elif (val < boundaries[1]):\n",
    "        return 'b'\n",
    "    elif (val < boundaries[2]):\n",
    "        return 'c'\n",
    "    else:\n",
    "        return 'd'\n",
    "\n",
    "#Function to convert a continuous data into labelled data\n",
    "#There are 4 lables  - a, b, c, d\n",
    "def toLabel(df, old_feature_name):\n",
    "    second = df[old_feature_name].mean()\n",
    "    minimum = df[old_feature_name].min()\n",
    "    first = (minimum + second)/2\n",
    "    maximum = df[old_feature_name].max()\n",
    "    third = (maximum + second)/2\n",
    "    return df[old_feature_name].apply(label, args= (first, second, third))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert all columns to labelled data\n",
    "df['sl_labeled'] = toLabel(df, 'sl')\n",
    "df['sw_labeled'] = toLabel(df, 'sw')\n",
    "df['pl_labeled'] = toLabel(df, 'pl')\n",
    "df['pw_labeled'] = toLabel(df, 'pw')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['sl', 'sw', 'pl', 'pw'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df['sl_labeled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function -: calculates entropy of the data \n",
    "\n",
    "def calculate_entropy(Y):\n",
    "    \n",
    "    Classes=set(Y[0])\n",
    "    entropy=0\n",
    "    total_rows=len(Y)\n",
    "    \n",
    "    for cl in Classes:\n",
    "        \n",
    "        rows_of_cl=(Y[0]==cl).sum()\n",
    "        probability=rows_of_cl/total_rows\n",
    "        \n",
    "        entropy+=-(probability*log2(probability))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree class-:\n",
    "#   current_entropy - stores the current entropy of Node          \n",
    "#   children - stores children of the Node\n",
    "#   target_values- stores a list of target classes\n",
    "#   target_values_rows - stores number of rows of target classes\n",
    "#   leaf_node - stores true if node is leaf node\n",
    "#   gain_ratio - stores gain ratio of feature at which we are splitting\n",
    "#   best_feature - stores feature at which dataset is splitting\n",
    "\n",
    "class Tree:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.current_entropy =None \n",
    "        self.children =[]\n",
    "        self.target_values=[]\n",
    "        self.target_values_rows=[]\n",
    "        self.leaf_node=False\n",
    "        self.gain_ratio=None\n",
    "        self.best_feature=None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(root,level):\n",
    "    \n",
    "    # the level of node\n",
    "    \n",
    "    print(\"Level\",level)\n",
    "    \n",
    "    # printing count of target classes\n",
    "    \n",
    "    for i in range(len(root.target_values)):\n",
    "        print(\"Count of\",root.target_values[i],\"=\",root.target_values_rows[i])\n",
    "    \n",
    "    \n",
    "    # printing current entropy of the node\n",
    "    \n",
    "    print(\"Current Entropy  is =\",root.current_entropy)\n",
    "    \n",
    "    # checking if node is a leaf node\n",
    "    \n",
    "    if(root.leaf_node==True):\n",
    "        print(\"Reached leaf Node\")\n",
    "        return \n",
    "\n",
    "    # checking if best features exist to split upon\n",
    "    \n",
    "    if(root.best_feature==None):\n",
    "        return \n",
    "    \n",
    "    # printing gain ratio of the feature at which we are splitting\n",
    "    \n",
    "    print(\"Splitting on feature\",root.best_feature,\"with gain ratio\",root.gain_ratio)\n",
    "    \n",
    "    # recursively calling children of the node\n",
    "    \n",
    "    for child in root.children:\n",
    "        \n",
    "        print()\n",
    "        print_tree(child,level+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(df, y, unused_features,root):\n",
    "    \n",
    "    total_rows=y.shape[0]\n",
    "    current_entropy=calculate_entropy(y)\n",
    "    \n",
    "    # storing count of target classes of node\n",
    "    \n",
    "    for Class in set(y[0]):\n",
    "        \n",
    "        totals_rows_of_Class=(y[0]==Class).sum()\n",
    "        \n",
    "        root.target_values.append( Class )\n",
    "        root.target_values_rows.append( totals_rows_of_Class)\n",
    "    \n",
    "    # storing current entropy of the node\n",
    "    \n",
    "    root.current_entropy=current_entropy\n",
    "   \n",
    "    # Case : if node is a leaf node\n",
    "  \n",
    "    if(len(root.target_values_rows)==1):\n",
    "        root.leaf_node=True\n",
    "        return\n",
    "    \n",
    "    # Case : if no features are available to split upon\n",
    "    \n",
    "    if(len(unused_features)==0):\n",
    "        return \n",
    "    \n",
    "    \n",
    "    best_feature =\"\"\n",
    "    best_gain_ratio=0\n",
    "    \n",
    "    # finding best feature to split upon\n",
    "    # splitting is base on gain ratio of the feature\n",
    "    \n",
    "    for f in unused_features:\n",
    "        \n",
    "        possible_values = set(df[f])\n",
    "        \n",
    "        split_index=0\n",
    "        entropy=0\n",
    "        \n",
    "        # find gain ratio of feature\n",
    "        \n",
    "        for value in possible_values:\n",
    "            \n",
    "            rows=(df[f]==value)\n",
    "            entropy_after_split=calculate_entropy(y[rows])\n",
    "            \n",
    "            probability=rows.sum()/total_rows\n",
    "            \n",
    "            \n",
    "            entropy+=probability*entropy_after_split\n",
    "            split_index+=-probability*log2(probability)\n",
    "        \n",
    "        gain_ratio=( current_entropy-entropy )/split_index\n",
    "        \n",
    "        # comparing gain_ratio with best_split_ratio\n",
    "        \n",
    "        if(gain_ratio>best_gain_ratio):\n",
    "            \n",
    "            best_gain_ratio=gain_ratio\n",
    "            best_feature=f\n",
    "    \n",
    "    #Case -: if no feature is found to split upon\n",
    "    \n",
    "    if(best_feature==\"\"):\n",
    "        return\n",
    "    \n",
    "    # storing best_gain_ratio and best_feature of node\n",
    "    \n",
    "    root.gain_ratio=best_gain_ratio\n",
    "    root.best_feature=best_feature\n",
    "    \n",
    "    new_unused_features=list(unused_features)\n",
    "    new_unused_features.remove(best_feature)\n",
    "    \n",
    "    # recursively splitting the dataset on best_feature\n",
    "    \n",
    "    for value in sorted(set(df[best_feature])):\n",
    "        \n",
    "        child=Tree()\n",
    "        root.children.append(child)\n",
    "        build_tree(df[df[best_feature]==value],y[df[best_feature]==value],new_unused_features,child)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(iris.target)\n",
    "unused_features =list(set(df.columns))\n",
    "\n",
    "# creating root node of tree\n",
    "root=Tree()\n",
    "\n",
    "# building the Tree\n",
    "build_tree(df, y, unused_features,root)\n",
    "\n",
    "# printing the tree\n",
    "print_tree(root,0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
